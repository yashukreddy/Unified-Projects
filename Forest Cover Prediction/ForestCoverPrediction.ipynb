{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a7516dd",
   "metadata": {},
   "source": [
    "#### Importing necessary libraries and data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb933e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "X = df.drop(columns=['Cover_Type'])  \n",
    "y = df['Cover_Type']  \n",
    "y = y - 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0fa1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0457dc4",
   "metadata": {},
   "source": [
    "#### Train-test split up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1738ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12f01746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [10:55:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(n_estimators=100, eval_metric=\"mlogloss\", random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "#y_pred_xgb = y_pred_xgb + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6fd933",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1cb5211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8601190476190477\n",
      "XGBoost Accuracy: 0.8743386243386243\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78       432\n",
      "           1       0.80      0.66      0.72       432\n",
      "           2       0.83      0.81      0.82       432\n",
      "           3       0.94      0.98      0.96       432\n",
      "           4       0.89      0.95      0.92       432\n",
      "           5       0.84      0.88      0.86       432\n",
      "           6       0.93      0.97      0.95       432\n",
      "\n",
      "    accuracy                           0.86      3024\n",
      "   macro avg       0.86      0.86      0.86      3024\n",
      "weighted avg       0.86      0.86      0.86      3024\n",
      "\n",
      "\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79       432\n",
      "           1       0.80      0.68      0.73       432\n",
      "           2       0.84      0.85      0.85       432\n",
      "           3       0.96      0.97      0.97       432\n",
      "           4       0.90      0.96      0.92       432\n",
      "           5       0.86      0.90      0.88       432\n",
      "           6       0.94      0.97      0.96       432\n",
      "\n",
      "    accuracy                           0.87      3024\n",
      "   macro avg       0.87      0.87      0.87      3024\n",
      "weighted avg       0.87      0.87      0.87      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"\\nXGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f9193",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning - XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8305b655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "1 fits failed out of a total of 324.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1512, in fit\n",
      "    train_dmatrix, evals = _wrap_evaluation_matrices(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py\", line 596, in _wrap_evaluation_matrices\n",
      "    train_dmatrix = create_dmatrix(\n",
      "                    ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1003, in _create_dmatrix\n",
      "    return QuantileDMatrix(\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 1573, in __init__\n",
      "    self._init(\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 1632, in _init\n",
      "    it.reraise()\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 569, in reraise\n",
      "    raise exc  # pylint: disable=raising-bad-type\n",
      "    ^^^^^^^^^\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 550, in _handle_exception\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 637, in <lambda>\n",
      "    return self._handle_exception(lambda: self.next(input_data), 0)\n",
      "                                          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py\", line 1402, in next\n",
      "    input_data(**self.kwargs)\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 626, in input_data\n",
      "    self.proxy.set_info(\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 954, in set_info\n",
      "    self.set_label(label)\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 1092, in set_label\n",
      "    dispatch_meta_backend(self, label, \"label\", \"float\")\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py\", line 1348, in dispatch_meta_backend\n",
      "    _meta_from_pandas_series(data, name, dtype, handle)\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py\", line 679, in _meta_from_pandas_series\n",
      "    _meta_from_numpy(data, name, dtype, handle)\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py\", line 1279, in _meta_from_numpy\n",
      "    _check_call(_LIB.XGDMatrixSetInfoFromInterface(handle, c_str(field), interface_str))\n",
      "  File \"C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py\", line 284, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:17:08] C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\data\\array_interface.cu:44: Check failed: err == cudaGetLastError() (0 vs. 46) : \n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\YASHU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.69345238 0.69146825 0.70634921 0.70386905        nan 0.71536045\n",
      " 0.77331349 0.76967593 0.78778108 0.78579696 0.79654431 0.79604828\n",
      " 0.81836971 0.8192791  0.82787698 0.82820767 0.83597884 0.83515212\n",
      " 0.76818783 0.76173942 0.8051422  0.79613095 0.82242063 0.81291336\n",
      " 0.83556548 0.83134921 0.85499339 0.85251323 0.86160714 0.85970569\n",
      " 0.85863095 0.85598545 0.86582341 0.86466601 0.86731151 0.86739418\n",
      " 0.80381944 0.79902447 0.82977844 0.82523148 0.84085648 0.83680556\n",
      " 0.85433201 0.84895833 0.86284722 0.85887897 0.86458333 0.86177249\n",
      " 0.86359127 0.86342593 0.86648479 0.86631944 0.86549272 0.8682209\n",
      " 0.68303571 0.67956349 0.70122354 0.69386574 0.71205357 0.70858135\n",
      " 0.76545966 0.76124339 0.7791832  0.77662037 0.79133598 0.78902116\n",
      " 0.81010251 0.79968585 0.82018849 0.81522817 0.82862103 0.82242063\n",
      " 0.77041997 0.76207011 0.80919312 0.79604828 0.82316468 0.8098545\n",
      " 0.83589616 0.8266369  0.85722553 0.84920635 0.86276455 0.85739087\n",
      " 0.85276124 0.85350529 0.86235119 0.86416997 0.86499669 0.86499669\n",
      " 0.80671296 0.80241402 0.83416005 0.82440476 0.84623016 0.83680556\n",
      " 0.85582011 0.85127315 0.86053241 0.86152447 0.8620205  0.86383929\n",
      " 0.86334325 0.86268188 0.86458333 0.86574074 0.86483135 0.86541005]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 300, 'subsample': 1}\n",
      "Optimized XGBoost Accuracy: 0.8826058201058201\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       432\n",
      "           1       0.81      0.70      0.75       432\n",
      "           2       0.86      0.85      0.85       432\n",
      "           3       0.95      0.97      0.96       432\n",
      "           4       0.90      0.95      0.93       432\n",
      "           5       0.88      0.91      0.89       432\n",
      "           6       0.95      0.97      0.96       432\n",
      "\n",
      "    accuracy                           0.88      3024\n",
      "   macro avg       0.88      0.88      0.88      3024\n",
      "weighted avg       0.88      0.88      0.88      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  \n",
    "    'max_depth': [3, 6, 9],  \n",
    "    'learning_rate': [0.01, 0.1, 0.2],  \n",
    "    'subsample': [0.8, 1],  \n",
    "    'colsample_bytree': [0.8, 1]  \n",
    "}\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(eval_metric=\"mlogloss\", random_state=42)\n",
    "\n",
    "# GridSearch\n",
    "grid_search = GridSearchCV(xgb_clf, param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "print(\"Optimized XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54026d72",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ba1fa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
      "Optimized Random Forest Accuracy: 0.8697\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79       432\n",
      "           1       0.80      0.67      0.73       432\n",
      "           2       0.86      0.84      0.85       432\n",
      "           3       0.94      0.98      0.96       432\n",
      "           4       0.89      0.94      0.92       432\n",
      "           5       0.85      0.90      0.87       432\n",
      "           6       0.94      0.97      0.95       432\n",
      "\n",
      "    accuracy                           0.87      3024\n",
      "   macro avg       0.87      0.87      0.87      3024\n",
      "weighted avg       0.87      0.87      0.87      3024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500, 1000],  \n",
    "    'max_depth': [10, 20, 30, 50, None],    \n",
    "    'min_samples_split': [2, 5, 10],        \n",
    "    'min_samples_leaf': [1, 2, 5],          \n",
    "    'max_features': ['sqrt', 'log2', None], \n",
    "    'bootstrap': [True, False]              \n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Randomized Search\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,  \n",
    "    cv=5,       \n",
    "    verbose=2,\n",
    "    n_jobs=-1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from tuning\n",
    "print(\"Best Parameters:\", rf_random.best_params_)\n",
    "\n",
    "y_pred = rf_random.best_estimator_.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Optimized Random Forest Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd97f194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
